{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ModelLeaf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a41a6a7c1015>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mModelLeaf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mModelLeafInfer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ModelLeaf'"
     ]
    }
   ],
   "source": [
    "import ModelLeaf\n",
    "from ModelLeafInfer import *\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUND_TRUTH_MIN_SIZE_COEFF = 0.05  # 0.03    0.05\n",
    "def _calculate_IoU(image_name, detected_masks, ground_truth_dir, single_mask=True):\n",
    "    # AZ start validation of single image\n",
    "    # TODO - log/results file\n",
    "\n",
    "    # get ground truth masks for this image\n",
    "    # note: this should be done only once for each validation image (if train, do it once at the beginning, not after each epoch).\n",
    "    image_name_prefix = image_name.split(\".\")[0] + \"_GT_\"\n",
    "    num_gt_masks = 0\n",
    "    h = detected_masks.shape[0]\n",
    "    w = detected_masks.shape[1]\n",
    "    gt_min_size = GROUND_TRUTH_MIN_SIZE_COEFF * GROUND_TRUTH_MIN_SIZE_COEFF * h * w\n",
    "    \n",
    "    gt_file_names = []\n",
    "    for root, dirs, files in os.walk(ground_truth_dir):\n",
    "        for file in files:\n",
    "            if file.startswith(image_name_prefix):\n",
    "                # read GT file, and use the GT only if num_pixels in mask > Threshold\n",
    "                tmp = np.array(Image.open(ground_truth_dir + file))\n",
    "                tmp_size = np.count_nonzero(tmp)\n",
    "                if tmp_size > gt_min_size:\n",
    "                    gt_file_names.append(file)\n",
    "                    num_gt_masks = num_gt_masks + 1\n",
    "\n",
    "    gt_masks = np.zeros([h,w,num_gt_masks])\n",
    "    for i in range(num_gt_masks):\n",
    "        curr_gt_file = ground_truth_dir + gt_file_names[i]\n",
    "        curr_mask = np.array(Image.open(curr_gt_file))\n",
    "        gt_masks[:,:,i] = curr_mask\n",
    "    # create empty IoU matrix M (num_ground_truth_masks x num detected_masks)\n",
    "    # note: if validation during training - this should be done after each epoch.\n",
    "    num_of_detected_masks = detected_masks.shape[2]\n",
    "    all_iou = np.zeros(shape=[num_gt_masks, num_of_detected_masks])\n",
    "\n",
    "    # fill IoU matrix\n",
    "    # for each mask m1 in ground truth\n",
    "    #   for each mask m2 in detected\n",
    "    #       M(m1,m2) = IoU(m1,m2)\n",
    "    for i in range(num_gt_masks):\n",
    "        mask_i = gt_masks[:,:,i]\n",
    "        for j in range(num_of_detected_masks):\n",
    "            mask_j = detected_masks[:,:,j]\n",
    "            intersection = np.logical_and(mask_i,mask_j)\n",
    "            union = np.logical_or(mask_i,mask_j)\n",
    "            numI = np.count_nonzero(intersection)\n",
    "            numU = np.count_nonzero(union)\n",
    "            all_iou[i,j] = numI/numU\n",
    "\n",
    "    # calculate total (or average) IoU\n",
    "    curr_score = 0\n",
    "    for i in range(num_gt_masks):\n",
    "        # find max value and indices of max value\n",
    "        max_iou = np.amax(all_iou)\n",
    "        curr_score = curr_score + max_iou\n",
    "        max_idx = np.argmax(all_iou)\n",
    "        max_idx_row, max_idx_col = divmod(max_idx, all_iou.shape[1])\n",
    "\n",
    "        # remove row/col of max value (set zeros)\n",
    "        for j in range(all_iou.shape[1]):\n",
    "            all_iou[max_idx_row,j] = 0\n",
    "        for j in range(all_iou.shape[0]):\n",
    "            all_iou[j,max_idx_col] = 0\n",
    "\n",
    "    if num_gt_masks > 0:\n",
    "        curr_score = curr_score / num_gt_masks\n",
    "    else:\n",
    "        curr_score = 1\n",
    "\n",
    "    return curr_score\n",
    "    # AZ end validation of single image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'collections' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-fe3d7bfa83f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mArgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamedtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Args'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'path output no_pictures no_contours model no_masks gt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m args = Args(path='/home/simonl/datasets/inference_input',\n\u001b[0;32m      4\u001b[0m            \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'out_dir'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m            \u001b[0mno_pictures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'collections' is not defined"
     ]
    }
   ],
   "source": [
    "Args = collections.namedtuple('Args', 'path output no_pictures no_contours model no_masks gt')\n",
    "\n",
    "args = Args(path='/home/simonl/datasets/inference_input',\n",
    "           output='out_dir',\n",
    "           no_pictures=False,\n",
    "           no_contours=False,\n",
    "           model='models/leaves20200104T1646/mask_rcnn_leaves_0009.h5',\n",
    "           no_masks=False,\n",
    "           gt='/home/simonl/datasets/gt_masks_single/')\n",
    "\n",
    "from mrcnn.model import MaskRCNN\n",
    "infer_path = args.path\n",
    "output = args.output\n",
    "do_pictures = not args.no_pictures\n",
    "do_contours = not args.no_contours\n",
    "model_path = args.model\n",
    "should_save_masks = not args.no_masks\n",
    "compare_to_gt = args.gt != \"\"\n",
    "gt_dir = args.gt\n",
    "\n",
    "# Retrieve images\n",
    "images = generate_images(infer_path)\n",
    "\n",
    "# Retrieve model path\n",
    "model_path = prompt_model(model_path)\n",
    "\n",
    "# Load model\n",
    "inference_config = get_inference_config(ModelLeafConfig)\n",
    "if not os.path.exists(output):\n",
    "    os.makedirs(output, exist_ok=True)\n",
    "model = MaskRCNN(mode=\"inference\", config=inference_config, model_dir=output)\n",
    "model.load_weights(model_path, by_name=True)\n",
    "model.set_log_dir()\n",
    "\n",
    "output_dir = model.log_dir\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Infer\n",
    "inference_dict = {}\n",
    "IoU_dict = {}\n",
    "for image_path in tqdm(list(images)):\n",
    "    inference_dict[image_path] = []\n",
    "    image_name = os.path.basename(image_path)\n",
    "    image = np.array(Image.open(image_path))\n",
    "    r = model.detect([image])[0]\n",
    "    if should_save_masks:\n",
    "        save_masks(r, output_dir, image_name)\n",
    "\n",
    "    if do_pictures:\n",
    "        output_file_path = os.path.join(output_dir, image_name)\n",
    "        visualize.save_instances(image, r['rois'], r['masks'], r['class_ids'],\n",
    "                                ['BG', 'leave'], r['scores'], save_to=output_file_path,)\n",
    "\n",
    "    if do_contours:\n",
    "        inference_dict[image_path], txt_contours  = get_contours(r)\n",
    "\n",
    "        for i, leaf_contour in enumerate(txt_contours):\n",
    "            for j, polygon_contour in enumerate(leaf_contour):\n",
    "                contour_file_name = os.path.join(output_dir, os.path.splitext(image_name)[0]) + \\\n",
    "                \"_\" + str(i).zfill(3) + \"_\" + str(j) + \".txt\"\n",
    "                np.savetxt(contour_file_name, polygon_contour, fmt='%.1f', delimiter=' , ')\n",
    "\n",
    "\n",
    "    if compare_to_gt:\n",
    "        IoU_dict[image_path] = _calculate_IoU(image_name, r['masks'], gt_dir)\n",
    "\n",
    "\n",
    "if do_contours:\n",
    "    with open(os.path.join(output_dir, CONTOUR_FILE_NAME), 'w') as f:\n",
    "        f.write(json.dumps(inference_dict, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'IoU_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-de06ef174b83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIoU_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'IoU_dict' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.dumps(IoU_dict, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
